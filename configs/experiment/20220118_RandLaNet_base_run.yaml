# @package _global_

logger:
  comet:
    experiment_name: "RandLaNet_base_run"

trainer:
  log_every_n_steps: 1
  overfit_batches: 1
  num_sanity_val_steps: 0
  min_epochs: 10
  max_epochs: 150
  check_val_every_n_epoch: 1
  # gpus: "1"

datamodule:
  batch_size: 32 # Large possible for faster training.
  subsample_size: 12500  # Aim for at least 10pts/mÂ²
  num_workers: 1

callbacks:
  early_stopping:
    patience: 20
    cooldown: 0

