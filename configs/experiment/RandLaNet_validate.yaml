# @package _global_

# Use a specified model to infer on the full validation set (i.e. Test dataloader)

# to execute this experiment run:
# python run.py experiment=example_simple.yaml

defaults:
  - override /trainer: default.yaml
  - override /model: point_net_model.yaml
  - override /datamodule: datamodule.yaml
  - override /callbacks: callbacks.yaml
  - override /logger: comet

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 12345

# ATTENTION : you need to override these manually in CLI 
# fit_the_model: false
# test_the_model: true

hydra:
  verbose: false

trainer:
  resume_from_checkpoint: "path/to/checkpoint"  # override
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  min_epochs: 1
  max_epochs: 100000
  check_val_every_n_epoch: 1
  # limit_test_batches: 1  # Disable to predict on all data

callbacks:
  save_preds:
    save_predictions: true

datamodule:
  use_val_data_at_test_time: True # Here we use val data instead of test data
  batch_size: 32
  subtile_width_meters: 50
  subsample_size: 12500  # Aim for at least 10pts/mÂ²
  subtile_overlap: 0
  num_workers: 1
  shuffle_train: false

model:
  model_architecture: "randla_net"
  loss: "FocalLoss"
  n_classes: 2
  alpha: 0.25
  lr: 0.001
  net:
    d_in: 10  # 3 + F
    num_classes: 2
    num_neighbors: 16 
    decimation: 4  # divide by decimation for each of the 4 local encoder.
