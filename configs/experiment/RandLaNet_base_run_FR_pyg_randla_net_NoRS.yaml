# @package _global_
defaults:
  - override /datamodule/transforms/preparations: no_random_subsampling.yaml
  - override /datamodule/transforms/augmentations: light.yaml

logger:
  comet:
    experiment_name: "Pyg RandLaNet - No Random Sampling (10 x 30000pts)"


# Smaller BS : 10 x 40 000 (max) == 400 000 pts i.e. previous budget of 32 x 12 500pts.
datamodule:
  batch_size: 10

trainer:
  num_sanity_val_steps: 2
  min_epochs: 100
  max_epochs: 150
  accumulate_grad_batches: 3  # b/c larger clouds will not fit in memory with original BS.
  # gpus: [1]

callbacks:
  early_stopping:
    patience: 20

