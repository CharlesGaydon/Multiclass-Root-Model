# @package _global_

defaults:
  - override /trainer: default.yaml
  - override /callbacks: finetuning.yaml
  - override /model: randla_net_model.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters
task:
  task_name: finetune

logger:
  comet:
    experiment_name: "RandLaNet-Debug-FineTune"

trainer:
  overfit_batches: 1
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  min_epochs: 10
  max_epochs: 30
  check_val_every_n_epoch: 1
  # gpus: [1]

callbacks:
  finetune:
    unfreeze_fc_end_epoch: 1
    unfreeze_decoder_train_epoch: 3

model:
    lr_scheduler: null
