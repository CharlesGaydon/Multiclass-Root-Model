seed: 12345
work_dir: ${hydra:runtime.cwd}
debug: false
print_config: true
ignore_warnings: true
trainer:
  _target_: pytorch_lightning.Trainer
  gpus: 0
  min_epochs: 300
  max_epochs: 400
  log_every_n_steps: 1
  weights_summary: null
  progress_bar_refresh_rate: 1
  auto_lr_find: false
  num_sanity_val_steps: 2
  accumulate_grad_batches: 3
datamodule:
  transforms:
    preparations:
      train:
        TargetTransform:
          _target_: myria3d.pctl.transforms.transforms.TargetTransform
          _args_:
          - ${dataset_description.classification_preprocessing_dict}
          - ${dataset_description.classification_dict}
        DropPointsByClass:
          _target_: myria3d.pctl.transforms.transforms.DropPointsByClass
        GridSampling:
          _target_: torch_geometric.transforms.GridSampling
          _args_:
          - 0.25
        MinimumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MinimumNumNodes
          _args_:
          - 300
        MaximumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MaximumNumNodes
          _args_:
          - 40000
        Center:
          _target_: torch_geometric.transforms.Center
      eval:
        TargetTransform:
          _target_: myria3d.pctl.transforms.transforms.TargetTransform
          _args_:
          - ${dataset_description.classification_preprocessing_dict}
          - ${dataset_description.classification_dict}
        DropPointsByClass:
          _target_: myria3d.pctl.transforms.transforms.DropPointsByClass
        CopyFullPos:
          _target_: myria3d.pctl.transforms.transforms.CopyFullPos
        CopyFullPreparedTargets:
          _target_: myria3d.pctl.transforms.transforms.CopyFullPreparedTargets
        GridSampling:
          _target_: torch_geometric.transforms.GridSampling
          _args_:
          - 0.25
        MinimumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MinimumNumNodes
          _args_:
          - 300
        MaximumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MaximumNumNodes
          _args_:
          - 40000
        CopySampledPos:
          _target_: myria3d.pctl.transforms.transforms.CopySampledPos
        Center:
          _target_: torch_geometric.transforms.Center
      predict:
        DropPointsByClass:
          _target_: myria3d.pctl.transforms.transforms.DropPointsByClass
        CopyFullPos:
          _target_: myria3d.pctl.transforms.transforms.CopyFullPos
        GridSampling:
          _target_: torch_geometric.transforms.GridSampling
          _args_:
          - 0.25
        MinimumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MinimumNumNodes
          _args_:
          - 300
        MaximumNumNodes:
          _target_: myria3d.pctl.transforms.transforms.MaximumNumNodes
          _args_:
          - 40000
        CopySampledPos:
          _target_: myria3d.pctl.transforms.transforms.CopySampledPos
        Center:
          _target_: torch_geometric.transforms.Center
    augmentations:
      x_flip:
        _target_: torch_geometric.transforms.RandomFlip
        _args_:
        - 0
        p: 0.5
      y_flip:
        _target_: torch_geometric.transforms.RandomFlip
        _args_:
        - 1
        p: 0.5
    normalizations:
      NullifyLowestZ:
        _target_: myria3d.pctl.transforms.transforms.NullifyLowestZ
      NormalizePos:
        _target_: myria3d.pctl.transforms.transforms.NormalizePos
        subtile_width: ${datamodule.subtile_width}
      StandardizeRGBAndIntensity:
        _target_: myria3d.pctl.transforms.transforms.StandardizeRGBAndIntensity
    augmentations_list: '${oc.dict.values: datamodule.transforms.augmentations}'
    preparations_train_list: '${oc.dict.values: datamodule.transforms.preparations.train}'
    preparations_eval_list: '${oc.dict.values: datamodule.transforms.preparations.eval}'
    preparations_predict_list: '${oc.dict.values: datamodule.transforms.preparations.predict}'
    normalizations_list: '${oc.dict.values: datamodule.transforms.normalizations}'
  _target_: myria3d.pctl.datamodule.hdf5.HDF5LidarDataModule
  data_dir: /mnt/store-lidarhd/projet-LHD/IA/PACASAM-SHARED-WORKSPACE/CGaydon/20230930_60k_basic_targetted/data/
  split_csv_path: /mnt/store-lidarhd/projet-LHD/IA/PACASAM-SHARED-WORKSPACE/CGaydon/20230930_60k_basic_targetted/data/split.csv
  hdf5_file_path: /var/data/CGaydon/myria3d_datasets/20230930_60k_basic_targetted.hdf5
  points_pre_transform:
    _target_: functools.partial
    _args_:
    - ${get_method:myria3d.pctl.points_pre_transform.lidar_hd.lidar_hd_pre_transform}
  pre_filter:
    _target_: functools.partial
    _args_:
    - ${get_method:myria3d.pctl.dataset.utils.pre_filter_below_n_points}
    min_num_nodes: 1
  tile_width: 1000
  subtile_width: 50
  subtile_overlap_train: 0
  subtile_overlap_predict: ${predict.subtile_overlap}
  batch_size: 10
  num_workers: 3
  prefetch_factor: 2
dataset_description:
  _convert_: all
  classification_preprocessing_dict:
    3: 5
    4: 5
    0: 1
    66: 65
    100: 1
    101: 1
  classification_dict:
    1: unclassified
    2: ground
    5: vegetation
    6: building
    9: water
    17: bridge
    64: lasting_above
  d_in: 9
  num_classes: 7
callbacks:
  log_code:
    _target_: myria3d.callbacks.comet_callbacks.LogCode
    code_dir: ${work_dir}/myria3d
  log_logs_dir:
    _target_: myria3d.callbacks.comet_callbacks.LogLogsPath
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: step
    log_momentum: true
  log_iou_by_class:
    _target_: myria3d.callbacks.logging_callbacks.LogIoUByClass
    classification_dict: ${dataset_description.classification_dict}
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: val/loss_epoch
    mode: min
    save_top_k: 1
    save_last: true
    verbose: true
    dirpath: checkpoints/
    filename: epoch_{epoch:03d}
    auto_insert_metric_name: false
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: val/loss_epoch
    mode: min
    patience: 6
    min_delta: 0
model:
  optimizer:
    _target_: functools.partial
    _args_:
    - ${get_method:torch.optim.Adam}
    lr: ${model.lr}
  lr_scheduler:
    _target_: functools.partial
    _args_:
    - ${get_method:torch.optim.lr_scheduler.ReduceLROnPlateau}
    mode: min
    factor: 0.5
    patience: 20
    cooldown: 5
    verbose: true
    min_lr: 0.001
  criterion:
    _target_: torch.nn.CrossEntropyLoss
    label_smoothing: 0.0
    ignore_index: 65
  _target_: myria3d.models.model.Model
  d_in: ${dataset_description.d_in}
  num_classes: ${dataset_description.num_classes}
  ckpt_path: null
  neural_net_class_name: PyGRandLANet
  neural_net_hparams:
    num_features: ${model.d_in}
    num_classes: ${model.num_classes}
    num_neighbors: 16
    decimation: 4
    return_logits: true
  interpolation_k: ${predict.interpolator.interpolation_k}
  num_workers: 4
  iou:
    _target_: functools.partial
    _args_:
    - ${get_method:torchmetrics.JaccardIndex}
    - ${model.num_classes}
    absent_score: 1.0
  momentum: 0.9
  monitor: val/loss_epoch
  lr: 0.003933709606504788
logger:
  comet:
    _target_: pytorch_lightning.loggers.comet.CometLogger
    api_key: ${oc.env:COMET_API_TOKEN}
    workspace: ${oc.env:COMET_WORKSPACE}
    project_name: ${oc.env:COMET_PROJECT_NAME}
    experiment_name: 20230930_60k_basic_targetted
    auto_log_co2: false
    disabled: false
task:
  task_name: predict
predict:
  src_las: /path/to/input.las
  output_dir: /path/to/output_dir/
  ckpt_path: trained_model_assets/20230930_60k_basic_targetted_epoch37_Myria3DV3.4.0.ckpt
  gpus: 0
  subtile_overlap: 0
  interpolator:
    _target_: myria3d.models.interpolation.Interpolator
    interpolation_k: 10
    classification_dict: ${dataset_description.classification_dict}
    probas_to_save: [building,ground]
    predicted_classification_channel: confidence
    entropy_channel: entropy
