<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; lidar-deep-segmentation 1.6.12 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> lidar-deep-segmentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/setup_install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/prepare_dataset.html">Preparing data for training [TODO]</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/make_predictions.html">Performing inference on new data [TODO]</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_to/add_new_data_signature.html">How to add a new data signature [TODO]</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_to/train_new_model.html">How to train new models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="background/interpolation.html">KNN-Interpolation to merge multiple predictions [TODO]</a></li>
<li class="toctree-l1"><a class="reference internal" href="background/data_optimization.html">Different ways to feed data from large scale point cloud to a neural network [TODO]</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apidoc/run.html">run</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.train.html">lidar_multiclass.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.predict.html">lidar_multiclass.predict</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.datamodules.html">lidar_multiclass.datamodules</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.models.html">lidar_multiclass.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.models.modules.html">lidar_multiclass.models.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.callbacks.html">lidar_multiclass.callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="apidoc/lidar_multiclass.utils.html">lidar_multiclass.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">lidar-deep-segmentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/introduction.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>Lidar-Deep-Segmentation is a deep learning library designed with a focused scope: the multiclass semantic segmentation of large scale, high density aerial Lidar points cloud.</p>
<p>The library implements the training of 3D Segmentation neural networks, with optimized data-processing and evaluation logics at fit time.
It allows for the evaluation of single-class IoU on the full point cloud, which results in reliable model evaluation.</p>
<p>Although the library can be easily extended with new neural network architectures or new data signatures, the library makes some opiniated choices. In particular, the RandLa-Net neural network architecture is the go-to choice for its reprensation power, conceptual simplicity, and speed.
Additionnaly, two data signatures are supported:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://geoservices.ign.fr/lidarhd">French Lidar HD</a>, produced by the French geographical Institute. The data is colorized with both RGB and Infrared. Therefore, data processing will include Infrared channel as well as NDVI.</p></li>
<li><p>Swiss Lidar from <a class="reference external" href="https://www.swisstopo.admin.ch/en/geodata/height/surface3d.html">SwissSurface3D (en)</a>, a similar initiative from the Swiss geographical institute SwissTopo. The data comes from the SwissSurface3D Lidar database and is not colorized, so we have to join it with SwissImage10 orthoimages database. The procedure is described in this standalone <a class="reference external" href="https://github.com/CharlesGaydon/Colorize-SwissSURFACE3D-Lidar">repository</a>.</p></li>
</ul>
<p>Lidar-Deep-Segmentation is built upon <a class="reference external" href="https://pytorch.org/">PyTorch</a>. It keeps the standard data format
from <a class="reference external" href="https://pytorch-geometric.readthedocs.io/">Pytorch-Geometric</a>.
Its structure was bootstraped from <a class="reference external" href="https://github.com/ashleve/lightning-hydra-template">this code template</a>,
which heavily relies on <a class="reference external" href="https://hydra.cc/">Hydra</a> and <a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning">Pytorch-Lightning</a> to
enable flexible and rapid iterations of deep learning experiments.</p>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Charles GAYDON.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>